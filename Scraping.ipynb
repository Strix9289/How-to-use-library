{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHI5g2tjsvXlkF0j5Sxq4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strix9289/How-to-use-library/blob/master/Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_smDj4kw9es"
      },
      "source": [
        "**クローリングとスクレイピング**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ-iRQIK2iCT"
      },
      "source": [
        "# urllib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihIhMPNd2lW5"
      },
      "source": [
        "#ライブラリの読み込み\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNJ-Ev3g4HEK"
      },
      "source": [
        "## ダウンロードして直接保存\n",
        "\n",
        "- **urlretrieve(url, savename)**：urlをダウンロードしてsavenameで現在のファイルに保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZVg7vhHxDiH",
        "outputId": "470d3d0f-7e4b-43ac-c10e-db85c8ce2805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像ファイルのアドレス\n",
        "url = \"https://www.library.osaka-u.ac.jp/img/main_image.png\"\n",
        "savename = \"test.png\"\n",
        "\n",
        "urllib.request.urlretrieve(url, savename)\n",
        "print(\"保存しました\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "保存しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CirVCJGZ5BSb"
      },
      "source": [
        "## ダウンロードして一時的にメモリに保存\n",
        "- **data = urlopen(url)**：\n",
        "- data.read() : メモリのデータを読み込む\n",
        "- data.decode('utf-8') : データを文字列に変換 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2vozVUo50IJ",
        "outputId": "0d739c6f-eeea-4193-db62-242316c836fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#一時的にメモリ上に取得\n",
        "mem = urllib.request.urlopen(url)\n",
        "\n",
        "# 読み込む\n",
        "mem = mem.read()\n",
        "\n",
        "with open(savename, mode='wb') as f:\n",
        "  f.write(mem)\n",
        "  print('保存しました')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "保存しました\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrbNwBBkqcS0"
      },
      "source": [
        "## urljoin\n",
        "**urljoin(base, \"追加\")**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_dU3l4PekOT"
      },
      "source": [
        "# BeautigulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-WK0YSWej8k"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbFt3JHZgHKw"
      },
      "source": [
        "## HTMLの解析（構造が浅い場合）\n",
        "- **soup = BeautifulSoup(html, 'html.parser')**  \n",
        "- **h1 = soup.html.body.h1**\n",
        "- **h1.string**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTy25f9ujUTm"
      },
      "source": [
        "# ライブラリを取り込む\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py8NW4FfjbjY"
      },
      "source": [
        "# HTMLを解析する \n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYseADR_gE6p"
      },
      "source": [
        "# 解析したいHTML\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "  <h1>見出し</h1>\n",
        "  <p>段落１</p>\n",
        "  <p>段落2</p>\n",
        "</body></html>\n",
        "\"\"\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZD3Oz2GikUZ",
        "outputId": "d549a04a-5ca3-488b-fda0-78e7ea049b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 任意の部分を抽出する \n",
        "h1 = soup.html.body.h1\n",
        "p1 = soup.html.body.p\n",
        "p2 = p1.next_sibling.next_sibling\n",
        "\n",
        "# 要素のテキストを表示する\n",
        "print(\"h1 = \" + h1.string)\n",
        "print(\"p  = \" + p1.string)\n",
        "print(\"p  = \" + p2.string)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1 = 見出し\n",
            "p  = 段落１\n",
            "p  = 段落2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6lflTxZjgAv"
      },
      "source": [
        "## HTMLの解析（idで探す）\n",
        "**find(id='title')**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z6K1Y-RhE4D"
      },
      "source": [
        "html = \"\"\"\n",
        "<html><body>\n",
        "  <h1 id=\"title\">タイトル</h1>\n",
        "  <p id=\"body\">本文</p>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "# HTMLを解析する \n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVWuJOAXjxG2",
        "outputId": "6d798119-47d8-4bd8-afca-277037087429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "title = soup.find(id=\"title\")\n",
        "body  = soup.find(id=\"body\")\n",
        "\n",
        "# テキスト部分を表示 \n",
        "print(\"title=\" + title.string)\n",
        "print(\"body=\"  + body.string)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title=タイトル\n",
            "body=本文\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GOIhPFvkFfG"
      },
      "source": [
        "## find_all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YuzYbhWj60o"
      },
      "source": [
        "html = \"\"\"\n",
        "<html><body>\n",
        "  <ul>\n",
        "    <li><a href=\"http://first_url\">first</a></li>\n",
        "    <li><a href=\"http://second_url\">second</a></li>\n",
        "  </ul>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "# HTMLを解析する \n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A-D1opglRze",
        "outputId": "dd721866-4f71-4be5-8188-c4b72c672544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# findAll()メソッドですべての<a>タグを取り出す\n",
        "links = soup.find_all(\"a\")\n",
        "\n",
        "# リンク一覧を表示 (href属性はattrsプロパティにて、説明テキストはstringプロパティにて取得できる)\n",
        "for a in links:\n",
        "    href = a.attrs['href']\n",
        "    text = a.string\n",
        "    print(text, \"->\", href) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first -> http://first_url\n",
            "second -> http://second_url\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhXxS2Jolj2I"
      },
      "source": [
        "## DOM要素の属性（タグ名の後にある各属性）を取り出す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sskboxpRlnK-",
        "outputId": "3e8134ef-1e9b-42a8-e8c0-ede0b6573b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "html = \"<p><a href='a.html'>test</a></p>\"\n",
        "soup = BeautifulSoup(html,\"html.parser\")\n",
        "\n",
        "#変数aに<a>を代入\n",
        "a = soup.p.a\n",
        "\n",
        "#attrsプロパティの方はdict、#href属性の値を確認\n",
        "type(a.attrs), a[\"href\"]\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, 'a.html')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ttqfqOdmTL-"
      },
      "source": [
        "## CSSセレクタを使う\n",
        "|メソッド|意味|\n",
        "|:--|:--|\n",
        "|soup.select_one()|CSSセレクタで要素を1つ取り出す|\n",
        "|soup.select()|CSSセレクタで要素を複数取り出しリスト型にする|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlw9oLgxlzle"
      },
      "source": [
        "# 解析対象となるHTML\n",
        "html = \"\"\"\n",
        "<html><body>\n",
        "<div id=\"mihon\">\n",
        "  <h1>タイトル</h1>\n",
        "  <ul class=\"items\">\n",
        "    <li>段落1</li>\n",
        "    <li>段落2</li>\n",
        "    <li>段落3</li>\n",
        "  </ul>\n",
        "</div>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "# HTMLを解析する\n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3dtVzrCmP-J",
        "outputId": "cc7dec67-f3d5-4786-8588-a3c491000f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 必要な部分をCSSクエリで取り出す\n",
        "# | タイトル部分を取得 --- (「>」で子要素にのみ適用)\n",
        "h1 = soup.select_one(\"div#mihon > h1\").string\n",
        "print(\"h1 =\", h1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h1 = タイトル\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JwleKkfmnxv",
        "outputId": "d5d1cdbe-c339-40ac-b115-e8811552e003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# | リスト部分を取得 --- (「>」で子要素にのみ適用)\n",
        "li_list = soup.select(\"div#mihon > ul.items > li\")\n",
        "for li in li_list:\n",
        "\tprint(\"li =\", li.string)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "li = 段落1\n",
            "li = 段落2\n",
            "li = 段落3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VssD92zxrRuH"
      },
      "source": [
        "## HTML内にあるリンクを抽出する\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m69lBxkYrPCv"
      },
      "source": [
        "def enum_links(html, base):\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    links = soup.select(\"link[rel='stylesheet']\") # CSSファイルを取得\n",
        "    links += soup.select(\"a[href]\") # リンク      # 参照先の相対パスをもつ<a>タグを取得\n",
        "    result = []\n",
        "    # href属性を取り出し、リンクを絶対パスに変換 --- <a>タグ内のhrefから絶対バスに変換\n",
        "    for a in links:\n",
        "        href = a.attrs['href']\n",
        "        url = urljoin(base, href)\n",
        "        result.append(url)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt5HZ5_Z5XWu"
      },
      "source": [
        "## ファイルをダウンロードし保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNZ7J1sM5pvj"
      },
      "source": [
        "def download_file(url):\n",
        "    o = urlparse(url)\n",
        "    savepath = \"./\" + o.netloc + o.path\n",
        "    if re.search(r\"/$\", savepath): # ディレクトリならindex.html\n",
        "        savepath += \"index.html\"\n",
        "    savedir = os.path.dirname(savepath)\n",
        "    # 既にダウンロード済み?\n",
        "    if os.path.exists(savepath): return savepath\n",
        "    # ダウンロード先のディレクトリを作成\n",
        "    if not os.path.exists(savedir):\n",
        "        print(\"mkdir=\", savedir)\n",
        "        makedirs(savedir)\n",
        "    # ファイルをダウンロード --- \n",
        "    try:\n",
        "        print(\"download=\", url)\n",
        "        urlretrieve(url, savepath)\n",
        "        time.sleep(1) # 礼儀として1秒スリープ --- \n",
        "        return savepath\n",
        "    except:\n",
        "        print(\"ダウンロード失敗:\", url)\n",
        "        return None        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaPICdZq4ot"
      },
      "source": [
        "## 処理済み判断\n",
        "HTMLではa->bへの参照とb->aの参照がある。\n",
        "\n",
        "よって、一度参照したページを管理することで無限に同じページをダウンロードしないようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woKiGsusmqQ9"
      },
      "source": [
        "# 処理済みページを保存するリスト\n",
        "proc_files = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YWhLEL35kcl"
      },
      "source": [
        "# HTMLを解析してダウンロードする関数 \n",
        "def analize_html(url, root_url):\n",
        "    savepath = download_file(url)\n",
        "    if savepath is None: return\n",
        "    if savepath in proc_files: return # 解析済みなら処理しない\n",
        "    proc_files[savepath] = True\n",
        "    print(\"analize_html=\", url)\n",
        "    # リンクを抽出 \n",
        "    html = open(savepath, \"r\", encoding=\"utf-8\").read()\n",
        "    links = enum_links(html, url)\n",
        "    for link_url in links:\n",
        "        # リンクがルート以外のパスを指していたら無視 \n",
        "        if link_url.find(root_url) != 0:\n",
        "            if not re.search(r\".css$\", link_url): continue #ただしCSSファイルの場合は読み込む\n",
        "        # HTMLか？\n",
        "        if re.search(r\".(html|htm)$\", link_url):\n",
        "            # 再帰的にHTMLファイルを解析\n",
        "            analize_html(link_url, root_url)\n",
        "            continue\n",
        "        # それ以外のファイル\n",
        "        download_file(link_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}